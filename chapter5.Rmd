# Homework 5

*This week we learnt about dimensionality reduction techniques.*

```{r}
date()
```

```{r}

#Loading the data
human <- read.table("~/IODS-project/data/human2.txt", sep="\t")
#Note: It's "human2" because I wanted to keep the "human.txt" wrangled for last week's exercise :-)

#Accessing necessary libraries
library(GGally)
library(tidyr)
library(corrplot)
library(FactoMineR)
library(dplyr)

```

# 1) Overview of 'human' data

The 'human' data analysed here consists of "human development indices" for different countries, by the United Nations Development Programme. 

Below is a graphical overview of the data, and summaries of the variables in it. 

```{r}

#Summary of the 'human' variables
summary(human)

#Visualizing the variables
ggpairs(human)

```

__Distribution of variables:___ Most variables are quite close to being normally distributed. However, especially MatMort (maternal mortality ratio) and AdolBirth (adolescent birth rate) are very skewed to the left, indicating that they have low values in most countries, with some countries having extremely high values.

We can also see that the values for GNI are very spread out. This has important implications for doing a PCA (a bit later in this exercise).

```{r}

#Calculating a correlation matrix and rounding it
cor_matrix <- cor(human) %>% round(digits=2)

#Visualizing the matrix with corrplot
corrplot(cor_matrix, method="circle", type = "upper", cl.pos = "b", tl.pos = "d", tl.cex = 0.6)

```

__Relationships between variables:___ The strongest correlations are between MatMort (maternal mortality) and EduExp (expected years of schooling), MatMort and AdolBirth (adolescent birth rate), MatMort and LifeExp (life expectancy), and EduExp and LifeExp. 

The correlation between e.g. LifeExp and EduExp is positive, and negative between LifeExp and MatMort.
  
# 2) Principal Component Analysis (PCA)

```{r}

#Perform PCA on non-standardized data (with the SVD method)
pca_human <- prcomp(human)

#Drawing a biplot of the PC representation and the original variables
biplot(pca_human, choices = 1:2, cex = c(0.8,1), col = c("grey40", "deeppink2"))

```

__Description:__ The plot describes the variability captured by the first two principal components. By definition, PC1 captures the maximum amount of variance from features in the original data. PC2 captures the maximum amount of variability left. 

However, because PCA is sensitive to the relative scaling of the original features, and assumes features with larger variance are more important than ones with smaller variance, this biplot is a bit hard to interpret. I think this is the reason why most of the features are clumped together and hard to read here. But to make some interpretation, the plot shows MatMort has by far the highest standard deviation (length of the arrow). Also, it clearly contributes to PC1, whereas GNI contributes to PC2 (direction of arrows).

Because of the issue of PCA being sensitive to scaling, the variables should be standardized. I will do that next, and repeat the analysis above.

```{r}
#Standardizing the variables
human_std <- scale(human)

#Printing out summaries of the standardized variables
summary(human_std)

#Performing PCA again (with the SVD method)
pca_human <- prcomp(human_std)

#Drawing biplot of the principal component representation and the original variables
biplot(pca_human, choices = 1:2, cex = c(0.8,1), col = c("grey40", "deeppink2"))

```

__Description:__ Now, the plot is easier to interpret (see explanation above). It displays two representations of the data. First, it shows the observations (countries) placed on x and y coordinates defined by the two principal components. Second, it visualizes the relationships of the original features with each other, and with the principal components.

The angle between the arrows here can be interpreted as the correlation between the features. Therefore, lab_sexratio (ratio of labour force participation by sex) and ParlRep (parliamentary representation by sex) are strongly positively correlated. The same is true e.g. for MatMort (maternal mortality ratio) and AdolBirth (adolescent birth rate).

The angle between the feature and a PC axis can be interpreted as the correlation between the two. Here, lab_sexratio and ParlRep (parliamentary representation by sex) are contributing to PC2, and the other features mostly to PC1. 

The length of the arrows corresponds to the features' standard deviation. I see no big difference between those for different variables.

The results are anyhow a bit different than with the non-standardized variables. For example GNI does not stand out in this plot, as it does in the previous one. 

__Interpretation of the PCs:__ I think the plot (with standardized data) shows that countries with high EduExp (expected years of schooling), edu_sex (high proportion of women with secondary education) and LifeExp (life expectancy) are very differentiated from countries with high MatMort (maternal mortality) and AdolBirth (adolescent birth rate). These variables contribute to PC1. 

Also, lab_sexratio (proportion of female labour force) and ParlRep (female parliamentary representation) are correlated with each other, and are basically the only variables to contribute to PC2.

#3) Overview of 'tea' data

```{r}

#Loading the 'tea' data
data(tea)

#Exploring the structure and dimensions
str(tea)
dim(tea)
#The dataset has 300 observations and 36 variables.

#Because there are so many variables, I will choose only a subset of them to analyse:
#Column names to keep in the dataset
keep_columns <- c("Tea", "How", "sugar", "where", "price", "age_Q", "sophisticated")

#Selecting the 'keep_columns' to create a new dataset
tea_time <- select(tea, one_of(keep_columns))

#Visualizing the dataset
gather(tea_time) %>% ggplot(aes(value)) + geom_bar() + theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 8)) + facet_wrap("key", scales = "free")

```

__Description:__ The dataset consists of answers to a questionnaire on tea. People were asked how they drink tea, what are their product's perception, and some personal details. All variables chosen here are categorical. Above are 7 variables that I chose.

#4) Multiple Correspondence Analysis (MCA)

This dataset consists of categorical variables, so I will use a Multiple Correspondence Analysis on it. 

```{r}

#Multiple correspondence analysis
mca <- MCA(tea_time, graph = FALSE)

#Summary of the model
summary(mca)

#Visualizing the MCA
plot(mca, invisible=c("ind"), habillage = "quali")


```

__Description:__ The plot and its colours are not very nice to look at, sorry. Anyway, the summary and plot show that the first dimension captures about 11% of the variance, and the second dimension about 8.5%. These are not particularly high values, so the other remaining dimensions still explain a lot of the variance here.

Looking at the plot, we can find some patterns of relationship between the variables. But to make it easier, I will use a bit different kind of plot for this data (below).

```{r}

#First, choosing the number of categories per variable
categories = apply(tea_time, 2, function(x) nlevels(as.factor(x)))
categories

#Making data frames
teatime_vars = data.frame(mca$var$coord, Variable = rep(names(categories), 
    categories))
teatime_obs = data.frame(mca$ind$coord)

#Plotting the variable categories
ggplot(data = teatime_vars, aes(x = Dim.1, y = Dim.2, label = rownames(teatime_vars))) + 
    geom_hline(yintercept = 0, colour = "gray70") + geom_vline(xintercept = 0, 
    colour = "gray70") + geom_text(aes(colour = Variable)) + ggtitle("MCA plot of variables") + theme_classic()


```

__Description:__ The distance between variable categories gives a measure of their similarity. So here for example, label "p_upscale" in the price variable is different from all other categories. But "Earl Gray" for the kind of tea and "sugar" (for, well, drinking the tea with sugar or not) are very similar. They are therefore correlated. Some other variables that stand out are e.g. "other" for what the tea is drunk with (if anything), and "tea shop" for where the tea is being bought. Drinking green tea ("green") also seems quite uncorrelated with anything else. 

We can also see that being from 45 to 59 years is correlated with thinking that drinking tea is sophisticated (if I understood this variable in the dataset correctly). 
